{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {
    "marimo": {
     "name": "setup"
    }
   },
   "outputs": [],
   "source": [
    "import marimo as mo\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from skimage import io, filters, morphology, exposure, feature\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hbol",
   "metadata": {},
   "source": [
    "Below is a practical, robust “detect → fit lattice → reconstruct → subpixel refine” pipeline that works well for circular-dot grids on dark backgrounds, even with rotation/perspective-ish tilt and a few missing dots.\n",
    "\n",
    "The core idea is:\n",
    "\n",
    "Enhance dots (background removal + DoG/LoG bandpass)\n",
    "\n",
    "Detect dot candidates (local maxima)\n",
    "\n",
    "Subpixel centroid refinement (fast quadratic fit or Gaussian fit)\n",
    "\n",
    "Fit the grid lattice (estimate 2 basis directions + spacings)\n",
    "\n",
    "Assign each detection to a (row, col) and reconstruct missing\n",
    "\n",
    "Optionally refine again at predicted grid locations for best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MJUe",
   "metadata": {},
   "outputs": [
    {
     "ename": "multiple-defs",
     "evalue": "The variable 'detect_dot_grid' was defined by another cell",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "from detect_dot_grid import detect_dot_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "Name `detect_dot_grid` is not defined. It was expected to be defined in",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):",
      "  File \"\", line 1, in <module>",
      "    grid, output_img = detect_dot_grid(image_path, rows=21, cols=17)",
      "                       ^^^^^^^^^^^^^^^",
      "NameError: name 'detect_dot_grid' is not defined",
      ""
     ]
    }
   ],
   "source": [
    "grid, output_img = detect_dot_grid(image_path, rows=21, cols=17)\n",
    "plt.imshow(output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {
    "marimo": {
     "name": "*ensure_2d_gray"
    }
   },
   "outputs": [],
   "source": [
    "def ensure_2d_gray(img):\n",
    "    \"\"\"\n",
    "    Convert possible (H,W,3/4) or (Z,H,W) into a single (H,W) float32 image.\n",
    "    \"\"\"\n",
    "    img = np.asarray(img)\n",
    "\n",
    "    # RGB / RGBA -> grayscale\n",
    "    if img.ndim == 3 and img.shape[-1] in (3, 4):\n",
    "        rgb = img[..., :3].astype(np.float32)\n",
    "        # standard luminance; you can also just do rgb.mean(-1)\n",
    "        img2 = (\n",
    "            0.2126 * rgb[..., 0] + 0.7152 * rgb[..., 1] + 0.0722 * rgb[..., 2]\n",
    "        )\n",
    "        return img2.astype(np.float32)\n",
    "\n",
    "    # Stack -> take max projection (often best for bright dots) or choose a slice\n",
    "    if img.ndim == 3 and img.shape[0] not in (3, 4):\n",
    "        # If it's (Z,H,W) use max projection; if it's (H,W,C) handled above\n",
    "        return img.max(axis=0).astype(np.float32)\n",
    "\n",
    "    # Already 2D\n",
    "    if img.ndim == 2:\n",
    "        return img.astype(np.float32)\n",
    "\n",
    "    raise ValueError(f\"Unsupported image shape: {img.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {
    "marimo": {
     "name": "*subpixel_peak_quadratic"
    }
   },
   "outputs": [],
   "source": [
    "def subpixel_peak_quadratic(patch3x3):\n",
    "    c = patch3x3[1, 1]\n",
    "    dxx = patch3x3[1, 2] - 2 * c + patch3x3[1, 0]\n",
    "    dyy = patch3x3[2, 1] - 2 * c + patch3x3[0, 1]\n",
    "    dx = 0.5 * (patch3x3[1, 2] - patch3x3[1, 0])\n",
    "    dy = 0.5 * (patch3x3[2, 1] - patch3x3[0, 1])\n",
    "    eps = 1e-12\n",
    "    offx = 0.0 if abs(dxx) < eps else -dx / dxx\n",
    "    offy = 0.0 if abs(dyy) < eps else -dy / dyy\n",
    "    offx = float(np.clip(offx, -0.75, 0.75))\n",
    "    offy = float(np.clip(offy, -0.75, 0.75))\n",
    "    return offy, offx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {
    "marimo": {
     "name": "*pca_rotate"
    }
   },
   "outputs": [],
   "source": [
    "# ---------- Lattice fit + forced 21x17 reconstruction ----------\n",
    "def pca_rotate(points_yx) -> (np.ndarray, np.ndarray, np.ndarray):\n",
    "    pts_xy = points_yx[:, ::-1].astype(np.float64)\n",
    "    ctr = pts_xy.mean(axis=0)\n",
    "    X = pts_xy - ctr\n",
    "    C = np.cov(X.T)\n",
    "    eigvals, eigvecs = np.linalg.eigh(C)\n",
    "    V = eigvecs[:, np.argsort(eigvals)[::-1]]  # 2x2\n",
    "\n",
    "    # V = eigvecs[:, np.argsort(eigvals)]\n",
    "    U = X @ V  # rotated coords\n",
    "    # If needed, enforce axis-0 to be the longer spread direction\n",
    "    # (Often not necessary, but helpful when only part of grid is visible)\n",
    "    if np.var(U[:, 0]) < np.var(U[:, 1]):\n",
    "        V = V[:, ::-1]\n",
    "        U = X @ V\n",
    "    return U, V, ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xref",
   "metadata": {
    "marimo": {
     "name": "*estimate_spacing_1d"
    }
   },
   "outputs": [],
   "source": [
    "def estimate_spacing_1d(vals):\n",
    "    v = np.sort(vals)\n",
    "    d = np.diff(v)\n",
    "    d = d[d > 1e-6]\n",
    "    if len(d) == 0:\n",
    "        return None\n",
    "    med = np.median(d)\n",
    "    d = d[d < 2.5 * med]  # reject large gaps\n",
    "    return float(np.median(d)) if len(d) else float(med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {
    "marimo": {
     "name": "*find_best_origin"
    }
   },
   "outputs": [],
   "source": [
    "def find_best_origin(U, dx, dy, nrows, ncols, nsteps=60):\n",
    "    \"\"\"\n",
    "    Search u0,v0 offsets over [0,dx) and [0,dy) to maximize inliers.\n",
    "    Returns (u0, v0).\n",
    "    \"\"\"\n",
    "    u = U[:, 0]\n",
    "    v = U[:, 1]\n",
    "\n",
    "    # base anchors near the min corner\n",
    "    u_min = np.percentile(u, 1)\n",
    "    v_min = np.percentile(v, 1)\n",
    "\n",
    "    best = None\n",
    "    best_score = -1\n",
    "\n",
    "    # scan fractional offsets\n",
    "    for fu in np.linspace(0, dx, nsteps, endpoint=False):\n",
    "        for fv in np.linspace(0, dy, nsteps, endpoint=False):\n",
    "            u0 = u_min - fu\n",
    "            v0 = v_min - fv\n",
    "\n",
    "            col = np.rint((u - u0) / dx).astype(int)\n",
    "            row = np.rint((v - v0) / dy).astype(int)\n",
    "\n",
    "            ok = (row >= 0) & (row < nrows) & (col >= 0) & (col < ncols)\n",
    "            score = int(ok.sum())\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best = (float(u0), float(v0))\n",
    "\n",
    "    return best, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYtC",
   "metadata": {
    "marimo": {
     "name": "*force_grid_origin"
    }
   },
   "outputs": [],
   "source": [
    "def force_grid_origin(U, dx, dy, nrows, ncols) -> (float, float):\n",
    "    \"\"\"\n",
    "    Choose (u0,v0) so that (u-u0)/dx spans exactly ncols and (v-v0)/dy spans nrows.\n",
    "    Using robust percentiles helps with missing points.\n",
    "    \"\"\"\n",
    "    u, v = U[:, 0], U[:, 1]\n",
    "\n",
    "    # Estimate extents of occupied grid (robust)\n",
    "    u_lo, u_hi = np.percentile(u, 2), np.percentile(u, 98)\n",
    "    v_lo, v_hi = np.percentile(v, 2), np.percentile(v, 98)\n",
    "\n",
    "    # Back-calculate an origin that makes the span match (ncols-1)*dx etc.\n",
    "    # If detection is partial, this still anchors reasonably.\n",
    "    u0 = u_hi - (ncols - 1) * dx\n",
    "    v0 = v_hi - (nrows - 1) * dy\n",
    "\n",
    "    # If that seems off (e.g., u0 > u_lo), fallback to low percentile anchor\n",
    "    if u0 > u_lo:\n",
    "        u0 = u_lo\n",
    "    if v0 > v_lo:\n",
    "        v0 = v_lo\n",
    "\n",
    "    return float(u0), float(v0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {
    "marimo": {
     "name": "*assign_points_to_grid"
    }
   },
   "outputs": [],
   "source": [
    "def assign_points_to_grid(U, dx, dy, u0, v0, nrows, ncols):\n",
    "    u, v = U[:, 0], U[:, 1]\n",
    "    col = np.round((u - u0) / dx).astype(int)\n",
    "    row = np.round((v - v0) / dy).astype(int)\n",
    "\n",
    "    # keep only in-range assignments\n",
    "    ok = (row >= 0) & (row < nrows) & (col >= 0) & (col < ncols)\n",
    "    return row, col, ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kclp",
   "metadata": {
    "marimo": {
     "name": "*assign_to_grid"
    }
   },
   "outputs": [],
   "source": [
    "def assign_to_grid(U, dx, dy):\n",
    "    \"\"\"\n",
    "    Given rotated points U[:,0]=u, U[:,1]=v and spacings dx,dy,\n",
    "    assign integer col,row using rounded coordinates relative to a robust origin.\n",
    "    \"\"\"\n",
    "    u = U[:, 0]\n",
    "    v = U[:, 1]\n",
    "\n",
    "    # robust origin: use low-percentile as approximate (top-left-ish) anchor\n",
    "    u0 = np.percentile(u, 5)\n",
    "    v0 = np.percentile(v, 5)\n",
    "\n",
    "    col = np.round((u - u0) / dx).astype(int)\n",
    "    row = np.round((v - v0) / dy).astype(int)\n",
    "\n",
    "    # shift so minimum is 0\n",
    "    col -= col.min()\n",
    "    row -= row.min()\n",
    "    return row, col, u0, v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emfo",
   "metadata": {
    "marimo": {
     "name": "*refine_at_predictions"
    }
   },
   "outputs": [],
   "source": [
    "# ---------- Final refinement at each grid location ----------\n",
    "\n",
    "\n",
    "def refine_at_predictions(\n",
    "    img, pred_yx, search_radius=5, bg_sigma=25, dog_sigma1=1.2, dog_sigma2=2.6\n",
    ") -> np.ndarray:\n",
    "    dog = preprocess_and_dog(img, bg_sigma, dog_sigma1, dog_sigma2)\n",
    "    H, W = dog.shape\n",
    "    refined = np.full(pred_yx.shape, np.nan, dtype=np.float32)\n",
    "\n",
    "    for r in range(pred_yx.shape[0]):\n",
    "        for c in range(pred_yx.shape[1]):\n",
    "            y0, x0 = pred_yx[r, c]\n",
    "            y0i, x0i = int(round(y0)), int(round(x0))\n",
    "            y1, y2 = (\n",
    "                max(1, y0i - search_radius),\n",
    "                min(H - 2, y0i + search_radius),\n",
    "            )\n",
    "            x1, x2 = (\n",
    "                max(1, x0i - search_radius),\n",
    "                min(W - 2, x0i + search_radius),\n",
    "            )\n",
    "            if y2 <= y1 or x2 <= x1:\n",
    "                continue\n",
    "\n",
    "            win = dog[y1 : y2 + 1, x1 : x2 + 1]\n",
    "            wy, wx = np.unravel_index(np.argmax(win), win.shape)\n",
    "            yy, xx = y1 + wy, x1 + wx\n",
    "\n",
    "            patch = dog[yy - 1 : yy + 2, xx - 1 : xx + 2]\n",
    "            offy, offx = subpixel_peak_quadratic(patch)\n",
    "            refined[r, c] = (yy + offy, xx + offx)\n",
    "\n",
    "    return refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hstk",
   "metadata": {
    "marimo": {
     "name": "*preprocess_and_dog"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_and_dog(img, bg_sigma=25, dog_sigma1=1.2, dog_sigma2=2.6):\n",
    "    img = img.astype(np.float32)\n",
    "    img = img - np.percentile(img, 1)\n",
    "    img = np.clip(img, 0, None)\n",
    "\n",
    "    bg = gaussian_filter(img, bg_sigma)\n",
    "    hp = np.clip(img - bg, 0, None)\n",
    "\n",
    "    g1 = gaussian_filter(hp, dog_sigma1)\n",
    "    g2 = gaussian_filter(hp, dog_sigma2)\n",
    "    dog = g1 - g2\n",
    "    dog = exposure.rescale_intensity(dog, in_range=\"image\", out_range=(0, 1))\n",
    "    return dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWHF",
   "metadata": {
    "marimo": {
     "name": "*detect_dots_subpixel"
    }
   },
   "outputs": [],
   "source": [
    "def detect_dots_subpixel(\n",
    "    img,\n",
    "    min_distance=5,\n",
    "    thresh_rel=0.2,\n",
    "    bg_sigma=25,\n",
    "    dog_sigma1=1.2,\n",
    "    dog_sigma2=2.6,\n",
    ") -> (np.ndarray, np.ndarray):\n",
    "    dog = preprocess_and_dog(img, bg_sigma, dog_sigma1, dog_sigma2)\n",
    "    coords = feature.peak_local_max(\n",
    "        dog,\n",
    "        min_distance=min_distance,\n",
    "        threshold_abs=thresh_rel * float(dog.max()),\n",
    "        exclude_border=False,\n",
    "    )\n",
    "    H, W = dog.shape\n",
    "    pts = []\n",
    "    for y, x in coords:\n",
    "        if 1 <= y < H - 1 and 1 <= x < W - 1:\n",
    "            patch = dog[y - 1 : y + 2, x - 1 : x + 2]\n",
    "            offy, offx = subpixel_peak_quadratic(patch)\n",
    "            pts.append((y + offy, x + offx))\n",
    "        else:\n",
    "            pts.append((float(y), float(x)))\n",
    "    return np.array(pts, np.float32), dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iLit",
   "metadata": {
    "marimo": {
     "name": "*reconstruct_grid_robust"
    }
   },
   "outputs": [],
   "source": [
    "def reconstruct_grid_robust(\n",
    "    points_yx, expected_shape=(21, 17), origin_scan_steps=60\n",
    "):\n",
    "    nrows, ncols = expected_shape\n",
    "\n",
    "    U, V, ctr = pca_rotate(points_yx)\n",
    "\n",
    "    dx = estimate_spacing_1d(U[:, 0])\n",
    "    dy = estimate_spacing_1d(U[:, 1])\n",
    "    if dx is None or dy is None:\n",
    "        raise RuntimeError(\n",
    "            \"Could not estimate grid spacing; too few detections.\"\n",
    "        )\n",
    "\n",
    "    (u0, v0), score = find_best_origin(\n",
    "        U, dx, dy, nrows, ncols, nsteps=origin_scan_steps\n",
    "    )\n",
    "\n",
    "    row, col, ok = assign_points_to_grid(U, dx, dy, u0, v0, nrows, ncols)\n",
    "\n",
    "    # predicted grid (u,v)\n",
    "    uu = u0 + dx * np.arange(ncols)\n",
    "    vv = v0 + dy * np.arange(nrows)\n",
    "    UU, VV = np.meshgrid(uu, vv)\n",
    "    pred_uv = np.stack([UU, VV], axis=-1)\n",
    "\n",
    "    # back to image coords\n",
    "    pred_xy = pred_uv @ V.T + ctr\n",
    "    pred_yx = pred_xy[..., ::-1].astype(np.float32)\n",
    "\n",
    "    # map detections to slots, resolve collisions by closest-to-pred\n",
    "    grid_map = {}\n",
    "    for i in np.where(ok)[0]:\n",
    "        r, c = int(row[i]), int(col[i])\n",
    "        if (r, c) not in grid_map:\n",
    "            grid_map[(r, c)] = i\n",
    "        else:\n",
    "            prev = grid_map[(r, c)]\n",
    "            pyx = pred_yx[r, c]\n",
    "            d_new = np.sum((points_yx[i] - pyx) ** 2)\n",
    "            d_old = np.sum((points_yx[prev] - pyx) ** 2)\n",
    "            if d_new < d_old:\n",
    "                grid_map[(r, c)] = i\n",
    "\n",
    "    return grid_map, pred_yx, (dx, dy), score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZHCJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Convenience wrapper ----------\n",
    "def find_grid_centroids(\n",
    "    img,\n",
    "    nrows=21,\n",
    "    ncols=17,\n",
    "    min_distance=5,\n",
    "    thresh_rel=0.2,\n",
    "    bg_sigma=25,\n",
    "    dog_sigma1=1.2,\n",
    "    dog_sigma2=2.6,\n",
    "    search_radius=5,\n",
    ") -> (np.ndarray, dict, np.ndarray, np.ndarray):\n",
    "    img = ensure_2d_gray(img)  # <-- ADD THIS LINE\n",
    "\n",
    "    pts_yx, dog = detect_dots_subpixel(\n",
    "        img,\n",
    "        min_distance=min_distance,\n",
    "        thresh_rel=thresh_rel,\n",
    "        bg_sigma=bg_sigma,\n",
    "        dog_sigma1=dog_sigma1,\n",
    "        dog_sigma2=dog_sigma2,\n",
    "    )\n",
    "\n",
    "    grid_map, pred_yx, _, _, _ = reconstruct_grid(\n",
    "        pts_yx, expected_shape=(nrows, ncols)\n",
    "    )\n",
    "    refined_yx = refine_at_predictions(\n",
    "        img,\n",
    "        pred_yx,\n",
    "        search_radius=search_radius,\n",
    "        bg_sigma=bg_sigma,\n",
    "        dog_sigma1=dog_sigma1,\n",
    "        dog_sigma2=dog_sigma2,\n",
    "    )\n",
    "\n",
    "    # final output: detected where available else refined else predicted\n",
    "    final = pred_yx.copy()\n",
    "    for r in range(nrows):\n",
    "        for c in range(ncols):\n",
    "            if (r, c) in grid_map:\n",
    "                final[r, c] = pts_yx[grid_map[(r, c)]]\n",
    "            elif not np.isnan(refined_yx[r, c, 0]):\n",
    "                final[r, c] = refined_yx[r, c]\n",
    "            # else keep pred_yx\n",
    "\n",
    "    return final, grid_map, pts_yx, dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROlb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_grid_centroids_robust(\n",
    "    img,\n",
    "    nrows=21,\n",
    "    ncols=17,\n",
    "    min_distance=6,\n",
    "    thresh_rel=0.18,\n",
    "    bg_sigma=15,\n",
    "    dog_sigma1=0.9,\n",
    "    dog_sigma2=1.8,\n",
    "    search_radius=4,\n",
    "    cluster_eps=35,\n",
    "    cluster_min_samples=10,\n",
    "    origin_scan_steps=60,\n",
    "):\n",
    "    img = ensure_2d_gray(img)\n",
    "\n",
    "    pts_yx, dog = detect_dots_subpixel(\n",
    "        img,\n",
    "        min_distance=min_distance,\n",
    "        thresh_rel=thresh_rel,\n",
    "        bg_sigma=bg_sigma,\n",
    "        dog_sigma1=dog_sigma1,\n",
    "        dog_sigma2=dog_sigma2,\n",
    "    )\n",
    "\n",
    "    # ✅ drop outliers (your screenshot shows you need this)\n",
    "    pts_yx_f = keep_largest_cluster(\n",
    "        pts_yx, eps=cluster_eps, min_samples=cluster_min_samples\n",
    "    )\n",
    "\n",
    "    grid_map, pred_yx, _, score = reconstruct_grid_robust(\n",
    "        pts_yx_f,\n",
    "        expected_shape=(nrows, ncols),\n",
    "        origin_scan_steps=origin_scan_steps,\n",
    "    )\n",
    "\n",
    "    refined_yx = refine_at_predictions(\n",
    "        img,\n",
    "        pred_yx,\n",
    "        search_radius=search_radius,\n",
    "        bg_sigma=bg_sigma,\n",
    "        dog_sigma1=dog_sigma1,\n",
    "        dog_sigma2=dog_sigma2,\n",
    "    )\n",
    "\n",
    "    final = pred_yx.copy()\n",
    "    for r in range(nrows):\n",
    "        for c in range(ncols):\n",
    "            if (r, c) in grid_map:\n",
    "                final[r, c] = pts_yx_f[grid_map[(r, c)]]\n",
    "            elif not np.isnan(refined_yx[r, c, 0]):\n",
    "                final[r, c] = refined_yx[r, c]\n",
    "\n",
    "    return final, grid_map, pts_yx_f, dog, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnkX",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/home/user/Dropbox/3DPTV_Illmenau/00000093_0000000018B72D72.png\"\n",
    "img = io.imread(image_path)\n",
    "img = ensure_2d_gray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TqIu",
   "metadata": {},
   "outputs": [],
   "source": [
    "man_bg = mo.ui.slider(1, 50, value=25, label=\"BG Sigma\")\n",
    "man_s1 = mo.ui.slider(0.1, 5.0, value=1.2, step=0.1, label=\"DoG Sigma 1\")\n",
    "man_s2 = mo.ui.slider(0.1, 10.0, value=2.6, step=0.1, label=\"DoG Sigma 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vxnm",
   "metadata": {},
   "outputs": [],
   "source": [
    "_dog_preview = preprocess_and_dog(\n",
    "    img,\n",
    "    bg_sigma=man_bg.value,\n",
    "    dog_sigma1=man_s1.value,\n",
    "    dog_sigma2=man_s2.value,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(_dog_preview[1200:2000, 500:1500], cmap=\"gray\")\n",
    "plt.title(\n",
    "    f\"DoG Preview: bg={man_bg.value}, s1={man_s1.value:.1f}, s2={man_s2.value:.1f}\"\n",
    ")\n",
    "plt.axis(\"off\")\n",
    "_plot = plt.gca()\n",
    "\n",
    "mo.vstack([man_bg, man_s1, man_s2, _plot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DnEU",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo.md(\"## Step 2: Tune Dot Detection\")\n",
    "man_min_dist = mo.ui.slider(1, 20, value=6, step=1, label=\"Min Distance\")\n",
    "man_thresh = mo.ui.slider(\n",
    "    0.01, 0.5, value=0.18, step=0.01, label=\"Threshold Rel\"\n",
    ")\n",
    "mo.vstack(\n",
    "    [\n",
    "        mo.md(\"### Step 2: Tune Dot Detection Parameters\"),\n",
    "        man_min_dist,\n",
    "        man_thresh,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ulZA",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_yx, _ = detect_dots_subpixel(\n",
    "    img,\n",
    "    min_distance=man_min_dist.value,\n",
    "    thresh_rel=man_thresh.value,\n",
    "    bg_sigma=man_bg.value,\n",
    "    dog_sigma1=man_s1.value,\n",
    "    dog_sigma2=man_s2.value,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.scatter(pts_yx[:, 1], pts_yx[:, 0], s=10, c=\"r\")\n",
    "plt.title(f\"Detected {len(pts_yx)} dots (thresh={man_thresh.value:.2f})\")\n",
    "plt.axis(\"off\")\n",
    "plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfG",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo.md(\"## Step 3: Grid Reconstruction\")\n",
    "man_scan_steps = mo.ui.slider(\n",
    "    10, 100, value=60, step=10, label=\"Origin Scan Steps\"\n",
    ")\n",
    "man_eps = mo.ui.slider(10, 100, value=35, step=1, label=\"Cluster Epsilon\")\n",
    "mo.vstack(\n",
    "    [\n",
    "        mo.md(\"### Step 3: Grid Reconstruction Parameters\"),\n",
    "        man_scan_steps,\n",
    "        man_eps,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Pvdt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter points\n",
    "pts_yx_f = keep_largest_cluster(pts_yx, eps=man_eps.value, min_samples=10)\n",
    "\n",
    "# Reconstruct\n",
    "grid_map, pred_yx, _, score = reconstruct_grid_robust(\n",
    "    pts_yx_f,\n",
    "    expected_shape=(21, 17),\n",
    "    origin_scan_steps=man_scan_steps.value,\n",
    ")\n",
    "\n",
    "print(f\"Grid score: {score}, Mapped points: {len(grid_map)}/{21 * 17}\")\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "# Plot detected points\n",
    "plt.scatter(\n",
    "    pts_yx_f[:, 1], pts_yx_f[:, 0], s=5, c=\"gray\", alpha=0.5, label=\"Detected\"\n",
    ")\n",
    "# Plot grid points\n",
    "found_y, found_x = [], []\n",
    "pred_y, pred_x = [], []\n",
    "for r in range(21):\n",
    "    for c in range(17):\n",
    "        y, x = pred_yx[r, c]\n",
    "        if (r, c) in grid_map:\n",
    "            found_y.append(y)\n",
    "            found_x.append(x)\n",
    "        else:\n",
    "            pred_y.append(y)\n",
    "            pred_x.append(x)\n",
    "\n",
    "plt.scatter(found_x, found_y, s=20, c=\"lime\", marker=\"+\", label=\"Mapped\")\n",
    "plt.scatter(pred_x, pred_y, s=15, c=\"red\", marker=\"x\", label=\"Predicted\")\n",
    "plt.legend(loc=\"lower right\", fontsize=\"small\")\n",
    "plt.title(\"Reconstructed Grid\")\n",
    "plt.axis(\"off\")\n",
    "plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZBYS",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo.md(\"## Step 4: Final Pipeline\")\n",
    "run_all_btn = mo.ui.run_button(label=\"Run Full Pipeline with Current Settings\")\n",
    "mo.vstack([run_all_btn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aLJB",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo.stop(not run_all_btn.value, mo.md(\"Click to run full pipeline\"))\n",
    "\n",
    "# Gather parameters\n",
    "p_bg = man_bg.value\n",
    "p_s1 = man_s1.value\n",
    "p_s2 = man_s2.value\n",
    "p_min_dist = man_min_dist.value\n",
    "p_thresh = man_thresh.value\n",
    "p_scan = man_scan_steps.value\n",
    "p_eps = man_eps.value\n",
    "\n",
    "# Run\n",
    "final_grid, final_map, final_pts, _, final_score = find_grid_centroids_robust(\n",
    "    img,\n",
    "    nrows=21,\n",
    "    ncols=17,\n",
    "    bg_sigma=p_bg,\n",
    "    dog_sigma1=p_s1,\n",
    "    dog_sigma2=p_s2,\n",
    "    min_distance=p_min_dist,\n",
    "    thresh_rel=p_thresh,\n",
    "    origin_scan_steps=p_scan,\n",
    "    cluster_eps=p_eps,\n",
    ")\n",
    "\n",
    "print(f\"Final Grid Score: {final_score}\")\n",
    "print(f\"Final Mapped Points: {len(final_map)}\")\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.scatter(\n",
    "    final_grid[:, :, 1], final_grid[:, :, 0], s=20, c=\"lime\", marker=\"+\"\n",
    ")\n",
    "plt.title(\"Final Result\")\n",
    "plt.axis(\"off\")\n",
    "plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nHfw",
   "metadata": {},
   "outputs": [
    {
     "ename": "multiple-defs",
     "evalue": "The variable 'detect_dot_grid' was defined by another cell",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "def detect_dot_grid(img_path, rows=21, cols=17, visualize=True):\n",
    "    \"\"\"\n",
    "    Detects a symmetric circular grid in an image using OpenCV.\n",
    "\n",
    "    Args:\n",
    "        img_path (str): Path to the image file.\n",
    "        rows (int): Number of rows in the grid.\n",
    "        cols (int): Number of columns in the grid.\n",
    "        visualize (bool): Whether to draw the detected grid on the image.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (grid, output_img)\n",
    "            grid (np.ndarray): Detected corner coordinates (N, 1, 2) or None if not found.\n",
    "            output_img (np.ndarray): Image with detected grid drawn (if visualize=True).\n",
    "    \"\"\"\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"Error: Image not found at {img_path}\")\n",
    "        return None, None\n",
    "\n",
    "    # Load image\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(\"Error: Failed to load image.\")\n",
    "        return None, None\n",
    "\n",
    "    # Setup Blob Detector (using tuned parameters or robust defaults)\n",
    "    params = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "    # Filter by Area\n",
    "    params.filterByArea = True\n",
    "    params.minArea = 10\n",
    "    params.maxArea = 10000\n",
    "\n",
    "    # Filter by Circularity\n",
    "    params.filterByCircularity = (\n",
    "        False  # Often safe to disable for perspective circles\n",
    "    )\n",
    "    params.minCircularity = 0.1\n",
    "\n",
    "    # Filter by Convexity\n",
    "    params.filterByConvexity = True\n",
    "    params.minConvexity = 0.87\n",
    "\n",
    "    # Filter by Inertia\n",
    "    params.filterByInertia = True\n",
    "    params.minInertiaRatio = 0.01\n",
    "\n",
    "    # Thresholds\n",
    "    params.minThreshold = 10\n",
    "    params.maxThreshold = 220\n",
    "\n",
    "    detector = cv2.SimpleBlobDetector_create(params)\n",
    "\n",
    "    # pattern_size is (columns, rows) for OpenCV\n",
    "    pattern_size = (cols, rows)\n",
    "\n",
    "    # Use CLUSTERING flag as it's often more robust for deformed grids\n",
    "    flags = cv2.CALIB_CB_SYMMETRIC_GRID | cv2.CALIB_CB_CLUSTERING\n",
    "\n",
    "    found, corners = cv2.findCirclesGrid(\n",
    "        img, pattern_size, flags=flags, blobDetector=detector\n",
    "    )\n",
    "\n",
    "    # Create output image\n",
    "    output_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    if found:\n",
    "        if visualize:\n",
    "            cv2.drawChessboardCorners(output_img, pattern_size, corners, found)\n",
    "        return corners, output_img\n",
    "    else:\n",
    "        print(\"Grid not found.\")\n",
    "        return None, output_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xXTn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Use the detected grid for Calibration\n",
    "grid_corners, grid_vis = detect_dot_grid(\n",
    "    img_path, rows=grid_rows.value, cols=grid_cols.value\n",
    ")\n",
    "\n",
    "if grid_corners is not None:\n",
    "    mo.md(\"### Grid Detected Successfully\")\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(grid_vis)\n",
    "    plt.title(f\"Detected Grid: {len(grid_corners)} points\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.gca()\n",
    "\n",
    "    # Prepare object points (3D)\n",
    "    # Assuming a square grid with some spacing (e.g. 1.0 unit)\n",
    "    # Note: For symmetric circles, the grid is orthogonal\n",
    "    rows = grid_rows.value\n",
    "    cols = grid_cols.value\n",
    "\n",
    "    # Create object points: (0,0,0), (1,0,0), (2,0,0) ....,(cols-1,rows-1,0)\n",
    "    objp = np.zeros((rows * cols, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:cols, 0:rows].T.reshape(-1, 2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [objp]  # 3d point in real world space\n",
    "    imgpoints = [grid_corners]  # 2d points in image plane.\n",
    "\n",
    "    # Calibrate Camera\n",
    "    img_shape = img_cv.shape[::-1]  # (width, height)\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "        objpoints, imgpoints, img_shape, None, None\n",
    "    )\n",
    "\n",
    "    print(f\"Calibration RMS Error: {ret}\")\n",
    "    print(f\"Camera Matrix:\\n{mtx}\")\n",
    "    print(f\"Distortion Coefficients:\\n{dist.ravel()}\")\n",
    "else:\n",
    "    mo.md(\"### Grid Detection Failed\")\n",
    "    print(\"Cannot proceed with calibration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AjVT",
   "metadata": {},
   "source": [
    "### Subpixel Refinement\n",
    "Do we need to run subpixel center finding?\n",
    "\n",
    "For symmetric circular grids detected using `cv2.findCirclesGrid` (especially with `SimpleBlobDetector`), the detected points are typically the centroids of the blobs. These centroids are already computed with sub-pixel precision (floating point coordinates).\n",
    "\n",
    "`cv2.cornerSubPix` is primarily designed for saddle points (checkerboards) where intensity gradients intersect. It relies on edge gradients which may not be ideal for the soft edges of a circle or might not improve upon the centroid method for circular features.\n",
    "\n",
    "Therefore, **explicit `cornerSubPix` refinement is usually not required** or recommended for circular grids if `SimpleBlobDetector` is used effectively. The blob detector's center-of-mass calculation serves as the sub-pixel refinement."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "marimo": {
   "app_config": {
    "auto_download": [
     "ipynb"
    ],
    "width": "medium"
   },
   "marimo_version": "0.19.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
